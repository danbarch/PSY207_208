---
title: "Differences Between Two Things IV"
subtitle: "Classical Effect Size & Power; Bayesian $t$-tests"
author: ""
date: "`r Sys.Date()`"
output: 
  xaringan::moon_reader:
    self_contained: true
    css: [soundmachine.css]
    nature: 
      # highlightStyle: none
      hilightLines: true
      highlightSpans: true

---

```{r setup, include=FALSE}
options(htmltools.dir.version = FALSE)
knitr::opts_chunk$set(warning = FALSE, message = FALSE)
library(tidyverse) # load tidyverse package
library(MASS)
library(ggplot2)
library(ggthemes)
library(kableExtra)
library(flextable)
library(officer)
library(cowplot)
library(xaringan)
library(xaringanthemer)
#library(gg3D)
library(leaflet)
library(maps)
library(fontawesome)
library(ggrepel)
library(DescTools)
library(renderthis)
library(ggtext)
library(ggimage)
library(ftExtra)
library(scales)
#library(gganimate)

## Function to sample from a Chi Squared Distribution
samplingchi<-function(n,size,df){
sampmean<-rep(NA,n)	                #create an empty vector where 
                                    #we will store the mean values

sampsd<-rep(NA,n)                   #create an empty vector where 
                                    #we will store our sd values

for (i in 1:n){		                  #indicate that we are repeating 
                                    #the operation n times
  
samp<-rchisq(size,df)	              #sample 'size' number of random (r) 
                                    #scores from a chi squared (chisq) 
                                    #distribution with df = df 

sampmean[i]<-mean(samp)			        #take the mean of those scores

sampsd[i]<-sd(samp)}			          #take the sd of those scores

sampdf<-data.frame(sampmean,sampsd)	#make a data frame out of the means 
                                    #and the standard deviations

return(sampdf)}	                    #the output of the function 
                                    #is the data frame

## Function to Sample from a Normal Distribution

samplingnorm<-function(n,size, mean, sd){
  sampmean<-rep(NA,n)	                #create an empty vector where 
                                      #we will store the mean values 
  
  sampsd<-rep(NA,n) 	                #create an empty vector where 
                                      #we will store the sd values 
  
  for (i in 1:n){ 		                #indicate that we are repeating 
                                      #the operation n times
    
    samp<-rnorm(size,mean,sd)	        #sample 'size' number of 
                                      #random (r) scores from a 
                                      #normal (norm) given mean and sd 
    
    sampmean[i]<-mean(samp)		        #take the mean of those scores
    
    sampsd[i]<-sd(samp)}			        #take the sd of those scores
  
  sampdf<-data.frame(sampmean,sampsd)	#make a data frame of the means 
                                      #and the standard deviations
  
  return(sampdf)}                     #the output of the function is 
                                      #the data frame

#set.seed(77)
#powernull.df<-samplingnorm(5000, 25, 0, 1)
#
#poweralt.df<-samplingnorm(5000, 25, 0.75, 1)
#
#save(powernull.df, poweralt.df, file = "effectsizepowerbayest.RData")

load("effectsizepowerbayest.RData")

## To create pdf version:

# setwd("~/Documents/PSY 208/PSY_207-208_23-24/Lectures")
# renderthis::to_pdf("Effect_size_Power_Bayesian_t.Rmd", complex_slides = TRUE)

## To create PowerPoint version:

# renderthis::to_pptx("One_sample_t_tests.Rmd", complex_slides = TRUE)

```

### Effect Size

Tests of statistical significance are based on the **likelihood of observed results**\* given the **null assumption**.

**Significance** is all about the **expected relative frequency** of observing the effect in **repeated samples**.

> If you saw a result once, would you see it again?

Classical statistical significance *alone* does not tell us about the **size of the effect**.

> If phenomena are *related*, how *related* are they?

> If phenomena are *different*, how *different* are they?

.footnote[
\* yada yada yada more extreme unobserved blah blah
]
---
### Effect Size

We have already covered one effect-size statistic: $r$ (and $r^2$), which is about the size of **relationships**

.pull-left[
Small $r$: **weak relationship**

```{r echo=FALSE, fig.height = 6}
## Weak correlation

set.seed(77)
# create the variance covariance matrix
sigma1<-rbind(c(1, 0.1), c(0.1, 1))
# create the mean vector
mu<-c(0, 0) 
# generate the multivariate normal distribution
df1<-as.data.frame(mvrnorm(n=1000, mu=mu, Sigma=sigma1)) %>% 
  rename(y = V1,
         x = V2) 

df1cor<-round(cor(df1$x, df1$y), 2)

ggplot(df1, aes(x, y))+
  geom_point(color="#5ac2ad")+
  labs(title = bquote(r==.(df1cor)))+
  theme_tufte(ticks=FALSE)+
  theme_xaringan(css_file = "soundmachine.css")+
  geom_smooth(se=FALSE, method = "lm", linewidth = 1.5)


```


]

.pull-right[
Big $r$: **strong relationship**

```{r echo=FALSE, fig.height = 6}
## Strong correlation

set.seed(77)
# create the variance covariance matrix
sigma1<-rbind(c(1, 0.9), c(0.9, 1))
# create the mean vector
mu<-c(0, 0) 
# generate the multivariate normal distribution
df2<-as.data.frame(mvrnorm(n=1000, mu=mu, Sigma=sigma1)) %>% 
  rename(y = V1,
         x = V2) 

df2cor<-round(cor(df2$x, df2$y), 2)

ggplot(df2, aes(x, y))+
  geom_point(color="#5ac2ad")+
  labs(title = bquote(r==.(df2cor)))+
  theme_tufte(ticks=FALSE)+
  theme_xaringan(css_file = "soundmachine.css")+
  geom_smooth(se=FALSE, method = "lm", linewidth = 1.5)


```
]
---
### Effect Size: Differences

.slightly-smaller[

> Ex. 1: In two behavioral economics experiments each with 2 independent groups, participants in **Group 1** are willing to pay 1 dollar more on average for an object than partipants in **Group 2**.

>> The pooled variance is **2 dollars**.

]
.pull-left[
Experiment A: $n = 10$

***

$$t_{obs}=1.58, n.s$$
]

.pull-right[
Experiment B: $n = 100$:

***

$$t_{obs}=5, p < 0.001$$
]

***

.slightly-smaller[
The **same difference**, with the **same variance** in observations, can be *not significant* with small $n$ and *significant* with larger $n$. 

**Rejecting $H_0$ ** depends a lot on the **amount** of evidence!
]
---

### Effect Size: Differences

.slightly-smaller[

> Ex. 2: In a *third* behavioral economics experiment with 2 independent groups, participants in **Group 1** are willing to pay *100 dollars* more on average for a product than partipants in **Group 2**.

>> The pooled variance is again 2 dollars.

]

.pull-left[
Experiment C: $n = 100$

***

$$t_{obs}=500, p < 0.001$$
]

.pull-right[
Experiment B: $n = 100$

***

$$t_{obs}=5, p < 0.001$$
]

.slightly-smaller[
The results of *both* Experiment B and Experiment C are statistically significant, with $p < 0.001$. 

But, the difference between a mean difference of 1 dollar and a mean difference of 100 dollars is probably pretty **meaningful**
]

---

### Effect Size: Differences

Small effects can be **significant**, *especially* with **large samples**

How do we evaluate differences without the influence of sample size?

> We *literally* **remove $n$ from the equation**.

> The effect size measure that goes with $t$-tests replaces the **standard error** in the $t_{obs}$ equation with the **standard deviation**.

---

### Effect Size: Cohen's $d$

.slightly-smaller[

The **Standardized Difference**, more commonly (and hilariously) known as **Cohen’s $d$**, is a measure of effect size used for differences between two things.

> The larger the **magnitude** of Cohen’s d, the larger the effect.

We standardize the difference
> $\bar{x}-\Delta;~\bar{d}-\mu_d;$ or $~\bar{x}_1-\bar{x}-1-\Delta$

by dividing by the **standard deviation** of the data.

> so, it's the difference as measured by $sd$'s

Allows us to compare a single effect size across different experiments without regard to the $n$ in a particular study 

> that is particularly helpful for **classical meta-analysis**

]

---

### Formula for Cohen's d

.pull-left[
### $$d=\frac{difference}{sd}$$

***

where the **difference** is identical to the numerator of the appropriate $t_{obs}$ statistic.
]

.pull-right[
>one-sample: 
>
$$d=\frac{\bar{x}-\Delta}{sd_x}$$

>repeated-measures: 
>
>$$d = \frac{\bar{d}-\mu_d}{sd_d}$$
>
>independent groups:
>
$$d = \frac{\bar{x}_1-\bar{x}_2-\Delta}{sd_{pooled}}$$
]

---

### Guidelines for Interpreting Cohen's $d$

.center[

$0.8$: **large**; an *obvious* effect

$0.5$: **medium**; a *visible* effect 

$0.2$: **small**; a *real effect* but *difficult to detect*
]

These are **only guidelines**:

> *there is a certain risk inherent in offering conventional operational definitions for those terms for use in power analysis in as diverse a field of inquiry as behavioral science* (Cohen, 1988)

As always with effect-size interpretation, *use your scientific judgment*.

---

### $d$ for One-sample $t$-test data

Example data:

>Sample mean $\bar{x} = 10$

>Sample standard deviation $sd_x = 7.25$

>Testing a difference from $0$

***

$$d=\frac{\bar{x}-\Delta}{sd_x}=\frac{10}{7.25}=1.38$$

.center[
$d$ is greater than 0.8, so we would say *this is a large effect*

.slightly-smaller[
(and cite Cohen)
]
]
---
### $d$ for Repeated-measures $t$-test data

Example data:

> Sample mean difference $\bar{d} = -1.36$

> Sample standard deviation $sd_d = 1.35$

> Testing a difference from $0$

***

$$d=\frac{\bar{d}-\mu_d}{sd_d}=\frac{-1.36}{1.35}=-1.01$$

.center[

By convention, we report the *magnitude* of $d$ (so, $d=1.01$).

$d$ is greater than 0.8, so we would say *this is a large effect*

.slightly-smaller[
(and cite Cohen)
]
]

---
### $d$ for Independent-groups $t$-test data

Example data:

> Sample difference of means $\bar{x}_1-\bar{x}_2 = -5.3$

> Pooled standard deviation $sd_p = 1.01$

> Testing a difference from $0$

***

$$d=\frac{\bar{x}_1-\bar{x}_2-\Delta}{sd_p}=\frac{-5.3}{1.01}=-5.25 \to 5.25$$

.center[

$d$ is greater than 0.8, so we would say *this is a large effect*

.slightly-smaller[
(and cite Cohen)
]
]

---
### Statistical Significance & Effect Size

You can have a **small effect size** for a significant effect, *especially* with **large $n$**

> Even though the differences are small, they are:

>> unlikely to have been found due to pure chance

>> likely to be found again in repeated sampling

Reporting sample size gives **context** for a significant effect.

---

### Statistical Significance & Effect Size

.slightly-smaller[

One **could** but **should not** and please promise me you **won't** also calculate an effect size for an effect that is *not significant*, (especially if $n$ is relatively small)
***

.pull-left[
>Example: 

One-sample $t$-test, $n = 15$, two-tailed hypothesis

Observed statistics: $\bar{x}=2.5,~sd_x=5,~se_x=1.29$

$$t_{obs}=1.94, p=0.07$$
$$d=\frac{\bar{x}}{sd_x}=\frac{2.5}{5}=0.5$$

]

.pull-right[

> If $H_0$ is not rejected, ***there is no effect***
>
> Reporting $d$ (or any other effect-size measure) for non-significant results is ***absurd***.
>
> (if something doesn't exist, how can we make statements about how big it is?)

]
]

---

### Classical Power

A reminder that there are **two mistakes** that we can make in **NHST**:

```{r echo=FALSE}
Decision<-c("Decision", "Decision")
Dec_Yes_No<-c("Reject \\(H_0\\)", "Continue to Assume \\(H_0\\)")
Yes<-c("Hit", cell_spec("Type-II Error", background="#fffaf1"))
No<-c(cell_spec("Type-I Error", background="#fffaf1"), "Correctly Assume \\(H_0\\)")

SDT_table<-data.frame(Decision, Dec_Yes_No, Yes, No)

kable(SDT_table,
      "html",
      escape=FALSE,
      col.names=c("",
                  "",
                  "Yes",
                  "No")) %>% 
  kable_styling() %>% 
  add_header_above(c(" "=2, "Real Effect?"= 2)) %>% 
  collapse_rows(columns=1)
```

---
### The Type-I Error

> Example: a repeated-measured design experiment with $n=25$. Steven Strange, MD\* is a co-author.

In this experiment, the **differences in the population** are distributed as a **standard normal**.
.pull-left[

```{r echo=FALSE, fig.height = 3}
d<-seq(-3, 3, 6/1000)
density<-dnorm(d)

data.frame(d, density) %>% 
  ggplot(aes(d, density))+
  geom_line(linewidth = 2)+
  theme_tufte(ticks=FALSE)+
  theme_xaringan(css_file = "soundmachine.css")
```

]

.pull-right[
```{r echo=FALSE, fig.align = 'center'}
knitr::include_graphics("images/timeline-doctor-strange.gif")

```

]
.footnote[
\* Dr. Strange has wizard powers and can see all possible outcomes of an event. For this example, I'm assuming he also knows the values of population parameters.
]

---

### The Type-I Error

.pull-left[

Dr. Strange sees **5,000** possible futures for the experiment and calculates **summary statistics $\bar{d}$ and $se_d$** for each one. 

```{r echo=FALSE}
null.mean.stats<-round(quantile(powernull.df$sampmean, c(0.1, 0.25, 0.5, 0.75, 0.9)), 3)

null.se.stats<-round(quantile(powernull.df$sampsd/5, c(0.1, 0.25, 0.5, 0.75, 0.9)), 3)

percentile<-c("10th",
              "25th",
              "median",
              "75th",
              "90th")

data.frame(percentile,
           unname(null.mean.stats),
           unname(null.se.stats)) %>% 
  kable("html",
        col.names=c("Percentile",
                    "\\(\\bar{d}\\)",
                    "\\(se_d\\)"),
        escape=FALSE) %>% 
  kable_styling()
```


]

.pull-right[


```{r echo=FALSE, fig.height = 8}
powernull.df %>% 
  ggplot(aes(sampmean/sampsd))+
  geom_histogram(binwidth = 0.05, color = "#c901a1")+
  theme_tufte(ticks=FALSE)+
  theme_xaringan(css_file = "soundmachine.css")+
  labs(x=bquote(t[obs]), y="frequency",
       title=bquote(t[obs]==frac(bar(d),se[d])))+
  scale_y_continuous(labels=label_number(suffix = "K", scale=1e-3))
```
]

---

### The Type-I Error

Let's assume we have a **two-tailed** test with ** $\alpha = 0.05$ **

> With $df=24$, any $|t_{obs}|\ge 2.064$ leads to rejecting $H_0$.

```{r echo=FALSE, fig.height = 6, fig.width = 12}
x<-powernull.df$sampmean/(powernull.df$sampsd/5)

tbigger<-sum(x>=2.064)
tsmaller<-sum(x<=-2.064)
tmid<-length(x)-tbigger-tsmaller

y<-runif(5000, 0.25, 0.75)
data.frame(x, y) %>% 
  ggplot(aes(x,y))+
  geom_point()+
  theme_tufte(ticks=FALSE)+
  theme_xaringan(css_file = "soundmachine.css")+
  geom_segment(aes(x=-2.06,
                   xend=-2.06,
                   y=0,
                   yend=Inf),
               lty=2)+
  geom_segment(aes(x=2.06,
                   xend=2.06,
                   y=0,
                   yend=Inf),
               lty=2)+
  annotate("text",
           x=c(-5, 0, 5),
           y=0,
           vjust=0,
           size=24/.pt,
           label=c("Type-I error",
                   "correctly continue\nto assume null",
                   "Type-I error"),
           color = c("#c901a1",
                     "#0331a1",
                     "#c901a1"))+
  annotate("text",
           x=-5,
           y=1,
           vjust=1,
           size=24/.pt,
           label=paste0(tsmaller, "\n (", 
                        round(100*tsmaller/length(x), 2), "%)"),
           color="#c901a1")+
    annotate("text",
           x=5,
           y=1,
           vjust=1,
           size=24/.pt,
           label=paste0(tbigger, "\n (", 
                        round(100*tbigger/length(x), 2), "%)"),
           color="#c901a1")+
      annotate("text",
           x=0,
           y=1,
           vjust=1,
           size=24/.pt,
           label=paste0(tmid, "\n (", 
                        round(100*tmid/length(x), 2), "%)"),
           color="#0331a1")+
  xlim(-7, 7)+
  ylim(0, 1)+
  labs(x=bquote(t[obs]))+
  theme(axis.text.y=element_blank(),
        axis.title.y = element_blank())
```

---

### The Type-II Error

The alternative hypothesis is that the data come from a population with a mean that is **literally anything other than zero**.

> If $\mu_d=0.75$, our results might look like this:


```{r echo=FALSE, fig.height = 6, fig.width = 12}
xalt<-poweralt.df$sampmean/(poweralt.df$sampsd/5)

taltbigger<-sum(xalt>=2.064)
taltsmaller<-sum(xalt<=-2.064)
taltmid<-length(xalt)-taltbigger-taltsmaller

y<-runif(5000, 0.25, 0.75)
data.frame(xalt, y) %>% 
  ggplot(aes(xalt,y))+
  geom_point()+
  theme_tufte(ticks=FALSE)+
  theme_xaringan(css_file = "soundmachine.css")+
  geom_segment(aes(x=-2.06,
                   xend=-2.06,
                   y=0,
                   yend=Inf),
               lty=2)+
  geom_segment(aes(x=2.06,
                   xend=2.06,
                   y=0,
                   yend=Inf),
               lty=2)+
  annotate("text",
           x=c(-5, 0, 5),
           y=0,
           vjust=0,
           size=24/.pt,
           label=c("Correct rejection",
                   "Type-II error",
                   "Correct rejection"),
           color = c("#0331a1",
                              "#c901a1",
                              "#0331a1"))+
  annotate("text",
           x=-5,
           y=1,
           vjust=1,
           size=24/.pt,
           label=paste0(taltsmaller, "\n (", 
                        round(100*taltsmaller/length(xalt), 2), "%)"),
           color = "#0331a1")+
    annotate("text",
           x=5,
           y=1,
           vjust=1,
           size=24/.pt,
           label=paste0(taltbigger, "\n (", 
                        round(100*taltbigger/length(xalt), 2), "%)"),
           color = "#0331a1")+
      annotate("text",
           x=0,
           y=1,
           vjust=1,
           size=24/.pt,
           label=paste0(taltmid, "\n (", 
                        round(100*taltmid/length(xalt), 2), "%)"),
           color = "#c901a1")+
  xlim(-7, 7)+
  ylim(0, 1)+
  labs(x=bquote(t[obs]))+
  theme(axis.text.y=element_blank(),
        axis.title.y = element_blank())
```

---

### Power

The **power** is the proportion of outcomes (in the wizard-seeing-the-future sense) where the null will be **correctly rejected** when $H_1$ is true.

```{r echo=FALSE, fig.height = 6, fig.width = 12}
x<-seq(-7, 7, 14/1000)
y<-dt(x, df=24, ncp = 0.75/(1/5))

nct_dist<-data.frame(x, y)

nct_dist %>% 
  ggplot(aes(x, y))+
  geom_line(linewidth = 1.5)+
  theme_tufte(ticks=FALSE)+
  theme_xaringan(css_file = "soundmachine.css")+
    geom_segment(aes(x=-2.06,
                   xend=-2.06,
                   y=0,
                   yend=Inf),
               lty=2)+
  geom_segment(aes(x=2.06,
                   xend=2.06,
                   y=0,
                   yend=Inf),
               lty=2)+
  geom_area(data=subset(nct_dist, nct_dist$x>2.06),
            fill="#5ac2ad")+
  geom_area(data=subset(nct_dist, nct_dist$x<2.06&nct_dist$x>-2.06),
            fill="#FF355E")+
  annotate("text",
           x=4,
           y=0.1,
           size=44/.pt,
           label="Power",
           color="#fffaf1",
           fontface="bold")+
    annotate("text",
           x=0,
           y=0.1,
           size=24/.pt,
           label="miss rate",
           color="#0331a1",
           fontface="bold")+
      annotate("text",
           x=-4,
           y=0.1,
           size=24/.pt,
           label="(technically\nalso power)",
           color="#0331a1",
           fontface="bold")+
        annotate("text",
           x=Inf,
           y=Inf,
           hjust=1,
           vjust=1,
           size=18/.pt,
           label="non-central\nt-distribution",
           color="#0331a1")+
  labs(title=bquote("Power (aka 1"~-beta~")"),
       subtitle=bquote("and miss rate (aka"~beta~")"))+
  theme(title=element_text(family="serif"))
```

---

### Factors associated with power

1. False alarm rate $(\alpha)$

2. Effect size

3. Number of observations $(n)$

4. Type of hypothesis (one- or two-tailed)

5. Statistical noise

6. Type of statistical test (*e.g.*, parametric or non-parametric)

---

### Power Analysis

Given the factors that go into the power of a test, we **stipulate some** and **solve for the others**

> Common examples: 

>> stipulate ** $\alpha$ and the statistical test** and examine the tradeoffs between ** $n$ and power** in a **power curve**

>> stipulate everything, including the **desired power** to get an estimate of the **required $n$ **.

---

### Power Analysis Example

> Dr. Strange has left the lab. We are on our own as far as making predictions go.

> We plan to do a **one-sample, one-tailed $t$-test with $\Delta=0$**

> We **stipulate** that our experiment will produce a **medium** effect\*, *specifically* $d=0.5$.

.center[
***How much power will we have if $n=30?$***
]

.footnote[
\*where do we get stipulations like that? Prior research and theory, mostly. Sometimes, it's principle (*e.g.* *if it's not a large effect we don't care!*). It is in all cases an **educated guess**.
]
---

### Power Analysis Example

We know from our close examination of Cohen's $d$ that:

$$d=\frac{\bar{x}-\Delta}{sd}$$
We know that the formula for a $t$-statistic is:

$$t=\frac{\bar{x}-0}{\frac{sd}{\sqrt{n}}}$$

Putting those two formulas together, if $d=1$, then:

$$t=d\left(\frac{1}{\frac{1}{\sqrt{n}}}\right)=0.5\sqrt{30}=2.74$$
---

### Power Analysis Example

.pull-left[
.slightly-smaller[
The **non-central $t$-distribution** gives us the distribution of $t$-statistics when ** $H_0$ is true**.

The sufficient statistics are ** $df$ ** and the **noncentrality parameter** 

$$\delta=\frac{\mu_0-\mu}{\sigma/\sqrt{n}}$$

... which we *just* estimated with a $t$ statistic.

]
]
.pull-right[

```{r echo=FALSE, fig.height = 5, fig.width = 6}
powercalc.df<-data.frame(x = seq(-4, 7, length.out = 10000),
                         y0=dt(seq(-4, 7, length.out = 10000),
                               df=29),
                         y1=dt(seq(-4, 7, length.out = 10000),
                               df=29,
                               ncp=2.74))
ggplot()+
  geom_line(data=powercalc.df, aes(x, y0),
            color="#710b79")+
  geom_line(data=powercalc.df, aes(x, y1),
            color="#0331a1")+
  theme_tufte(ticks=FALSE, base_size=24/.pt)+
  theme_xaringan(css_file = "soundmachine.css")+
    labs(x = bquote(t), y = "Probability")+
  annotate("text",
           x=1.5,
           y=0,
           label=bquote(t[crit]==1.699),
           color="#0331a1",
           size=24/.pt,
           hjust=1,
           vjust=1)+
    annotate("text",
           x=-2,
           y=0.3,
           label=bquote(H[0]~"curve"),
           color="#0331a1",
           size=24/.pt,
           hjust=0.5,
           vjust=0.5)+
  annotate("text",
           x=2.74,
           y=0.4,
           label=bquote(delta==2.74),
           color="#0331a1",
           size=24/.pt,
           hjust=0, 
           family="serif")+
  geom_area(data=subset(powercalc.df, powercalc.df$x>=qt(0.05, df=29, lower.tail=FALSE)),
            aes(x, y1),
            fill="#5ac2ad")+
    geom_segment(aes(x=qt(0.05, df=29, lower.tail=FALSE),
                   xend=qt(0.05, df=29, lower.tail=FALSE),
                   y=0,
                   yend=Inf),
               linetype = "dashed",
               color="#c901a1",
               size=1.25)+
    annotate("text",
           x=5,
           y=0.2,
           label="power",
           color="#0331a1",
           size=48/.pt,
           hjust=0.5)+
  ylim(-0.05, NA)+
  scale_x_continuous(breaks=c(0, 5))

```

]

.center[
The area under the non-central $t$ curve (given $df, \delta$) in the **rejection region** is the **power**
]

---

### Power Analysis Example

.pull-left[

```{r}
pt(1.699,
   df = 29,
   ncp = 2.74,
   lower.tail=FALSE)
```

]
.pull-right[

```{r echo=FALSE, fig.height = 5, fig.width = 6}
powercalc.df<-data.frame(x = seq(-4, 7, length.out = 10000),
                         y0=dt(seq(-4, 7, length.out = 10000),
                               df=29),
                         y1=dt(seq(-4, 7, length.out = 10000),
                               df=29,
                               ncp=2.74))
ggplot()+
  geom_line(data=powercalc.df, aes(x, y0),
            color="#710b79")+
  geom_line(data=powercalc.df, aes(x, y1),
            color="#0331a1")+
  theme_tufte(ticks=FALSE, base_size=24/.pt)+
  theme_xaringan(css_file = "soundmachine.css")+
    labs(x = bquote(t), y = "Probability")+
  annotate("text",
           x=1.5,
           y=0,
           label=bquote(t[crit]==1.699),
           color="#0331a1",
           size=24/.pt,
           hjust=1,
           vjust=1)+
    annotate("text",
           x=-2,
           y=0.3,
           label=bquote(H[0]~"curve"),
           color="#0331a1",
           size=24/.pt,
           hjust=0.5,
           vjust=0.5)+
  annotate("text",
           x=2.74,
           y=0.4,
           label=bquote(delta==2.74),
           color="#0331a1",
           size=24/.pt,
           hjust=0, 
           family="serif")+
  geom_area(data=subset(powercalc.df, powercalc.df$x>=qt(0.05, df=29, lower.tail=FALSE)),
            aes(x, y1),
            fill="#5ac2ad")+
    geom_segment(aes(x=qt(0.05, df=29, lower.tail=FALSE),
                   xend=qt(0.05, df=29, lower.tail=FALSE),
                   y=0,
                   yend=Inf),
               linetype = "dashed",
               color="#c901a1",
               size=1.25)+
    annotate("text",
           x=5,
           y=0.2,
           label="power",
           color="#0331a1",
           size=48/.pt,
           hjust=0.5)+
  ylim(-0.05, NA)+
  scale_x_continuous(breaks=c(0, 5))

```

]

.center[
The power is $1-\beta=0.85$: we will correctly reject $H_0$ ~85% of the time given our stipulations $(d, \alpha, n)$
]

---

### Power analysis for $t$-tests in `R`

```{r}
library(pwr)

pwr.t.test(n = 30,
           d = 0.5,
           sig.level = 0.05, 
           type = "one.sample",
           alternative = "greater")
```

---
### Power analysis for $t$-tests in `R`

Let's solve for $n$ given a **desired power** of $1-\beta=0.8$

```{r}
pwr.t.test(power = 0.8,
           d = 0.5,
           sig.level = 0.05, 
           type = "one.sample",
           alternative = "greater")
```

.footnote[
`n = 26.13753` means **you need 27**. Always round up!
]

---

### Power analysis for $t$-tests in `R`

Let's make a **power curve**


```{r fig.height = 5, fig.width = 12}
plot(pwr.t.test(power = 0.8, d = 0.5, sig.level = 0.05, 
                type = "one.sample", alternative = "greater"))
```

---

### Pedantry corner: Power Analysis

The concept of power is only important **before your experiment starts**

> Power refers to the rate at which that you will find a significant effect if the effect is actually real.

> Once you've run your experiment, the thing either happened or it didn't.

Sometimes, researchers will report **expected power** for a non-significant result *after the fact*

> Don’t do that. It’s just as silly as reporting effect size for a non-significant result.

---
  
### Bayesian $t$-tests

**Finally** (as in: in the last decade or so), there's a way to do **Bayesian $t$-tests** with a minimum of coding and no actual calculusing.

> Honestly, classical $t$-tests would be pretty tricky, too, if we had to do all the calculus.

---

### Bayes Factor

Change from **prior odds** to **posterior odds** between *model 1* and *model 0*:

$$BF_{10}=\left(\frac{p(H_1)}{p(H_0)}\right)\left(\frac{p(D|H_1)}{p(D|H_0)}\right)$$

We interpret the Bayes Factor as **how much more probable model 1 is than model 2 given the data**.

> for example: $BF_{10}=20$ means model 1 is 20 times more probable than model 0

>> also, in that example, $BF_{01}=\frac{1}{BF_{10}}=\frac{1}{20}$

---

### Bayes Factor

.slightly-smaller[

A Bayes Factor is relatively easy to compute when testing models that differ by **specific, unitary parameter values**, for example, two binomial models with $\pi_1=0.9$ and $\pi_0 = 0.5$, respectively:

$$BF_{10}=\frac{p(s\ge s_{obs}|\pi=0.9, N)}{p(s \ge s_{obs}|\pi=0.5, N)}$$
Otherwise, the priors and the likelihoods are **integrated** across **sets** of parameter values:

$$BF_{10}=\frac{\int p(D|\theta_{H_1})p(\theta_{H_1})d\theta_{H_1}}{\int p(D|\theta_{H_0})p(\theta_{H_0})d\theta_{H_0}}$$
where $\theta$ represents the model parameter(s). 

This is extra tricky if the parameter space is **unbounded** (_i.e._, if $\theta$ could be anywhere from $-\infty \to + \infty$)

]
---

### Bayesian $t$-test Model (IG example)

.center[
The concept:
]

.pull-left[

.slightly-smaller[

The **Effect size** for independent groups is 

$$d=\frac{\bar{x}_1-\bar{x}_2}{sd_p}$$ 

At the **population level**, we can call that 

$$\delta=\frac{\mu_1-\mu_2}{\sigma_p}$$
]
]

.pull-right[

.slightly-smaller[
The **difference between the population means** can be expressed as ** $\sigma\delta$ **

```{r echo=FALSE, fig.height = 5}
x1<-seq(-6, 0, 6/1000)
y1<-dnorm(x1, mean = -3)
x2<-seq(-3, 3, 6/1000)
y2<-dnorm(x2)

data.frame(x=c(x1, x2),
           y=c(y1, y2),
           labels=c(rep("x1", length(x1)),
                    rep("x2", length(x2)))) %>% 
  ggplot(aes(x, y, color=labels)) + 
  geom_line(linewidth = 1.5) + 
  theme_tufte(ticks=FALSE) + 
  theme_xaringan(css_file = "soundmachine.css") +
  geom_segment(aes(x=-3,
                   xend=0,
                   y=dnorm(0)+0.025,
                   yend=dnorm(0)+0.025),
               color="#5ac2ad", 
               linewidth = 2)+
    geom_segment(aes(x=-3,
                   xend=-3,
                   y=dnorm(0)+0.0125,
                   yend=dnorm(0)+0.0325),
               color="#5ac2ad", 
               linewidth = 2)+
      geom_segment(aes(x=0,
                   xend=0,
                   y=dnorm(0)+0.0125,
                   yend=dnorm(0)+0.0325),
               color="#5ac2ad", 
               linewidth = 2)+
  scale_color_manual(values=c("#0331a1",
                                       "#0331a1"),
                                       guide = NULL)+
  annotate("text",
           x=-1.5,
           y=dnorm(0)+0.05,
           vjust=0,
           label=bquote(mu[1]-mu[2]==sigma~delta),
           family = "serif",
           size=36/.pt)+
  expand_limits(y=0.5)+
  theme(axis.text=element_blank(),
        axis.title = element_blank())
```

]
]

---

### Bayesian $t$-test Model (IG)


```{r echo=FALSE, fig.height = 4, fig.width = 12}
x1<-seq(-6, 0, 6/1000)
y1<-dnorm(x1, mean = -3)
x2<-seq(-3, 3, 6/1000)
y2<-dnorm(x2)

data.frame(x=c(x1, x2),
           y=c(y1, y2),
           labels=c(rep("x1", length(x1)),
                    rep("x2", length(x2)))) %>% 
  ggplot(aes(x, y)) + 
  geom_line(aes(color=labels), linewidth = 1.5) + 
  theme_tufte(ticks=FALSE) + 
  theme_xaringan(css_file = "soundmachine.css") +
  geom_segment(aes(x=-3,
                   xend=0,
                   y=dnorm(0)+0.025,
                   yend=dnorm(0)+0.025),
               color="dodgerblue")+
  scale_color_manual(values=c("#0331a1",
                                       "#c901a1"),
                                       guide = NULL)+
    geom_segment(aes(x=-1.5,
                   xend=-1.5,
                   y=0,
                   yend=dnorm(0)+0.025),
               color="dodgerblue")+
  annotate("text",
           x=-1.5,
           y=dnorm(0)+0.05,
           vjust=0,
           label=bquote(sigma~delta),
           family = "serif",
           size=36/.pt,
           color="dodgerblue")+
    annotate("text",
           x=-1.5,
           y=0,
           vjust=0,
           hjust=1,
           label=expression(mu),
           family = "serif",
           size=48/.pt,
           color="dodgerblue")+
      annotate("text",
           x=0.6,
           y=dnorm(0)+0.025,
           vjust=0.5,
           hjust=0,
           label=bquote(mu+frac(sigma~delta, 2)),
           family = "serif",
           size=48/.pt,
           color = "#c901a1")+
        annotate("text",
           x=-3.6,
           y=dnorm(0)+0.025,
           vjust=0.5,
           hjust=1,
           label=bquote(mu-frac(sigma~delta, 2)),
           family = "serif",
           size=48/.pt,
           color = "#0331a1")+
      geom_segment(aes(x=0,
                   xend=0,
                   y=0,
                   yend=dnorm(0)),
               color="#c901a1",
               lty=2)+
        geom_segment(aes(x=-3,
                   xend=-3,
                   y=0,
                   yend=dnorm(0)),
               color="#0331a1",
               lty=2)+
  expand_limits(y=0.5)+
  theme(axis.text=element_blank(),
        axis.title = element_blank())
```
.slightly-smaller[
In this **generic** model, if the observed values in Group 1 for Participant $i$ are $y_{1i}$ and the observed values in Group 2 for Participant $i$ are $y_{2i}$, then:
]

.pull-left[


$$y_{1i}\sim N\left(\mu+\frac{\sigma\delta}{2}, \sigma^2\right)$$

]

.pull-right[
$$y_{2i}\sim N\left(\mu-\frac{\sigma\delta}{2}, \sigma^2\right)$$
]

---

### Bayesian $t$-test Hypotheses

.slightly-smaller[

Similarly to classical NHST (and that's on purpose), there is a **null model** which represents **nothing special going on** and an **alternative model** which represents the opposite.
  
  > Null: the observed $t$ values are sample means divided by standard errors with **no effect**

]

  $$Model_0: t \sim \frac{\bar{x}}{se}$$

.slightly-smaller[

> Alternative: there is a **nonzero value of $\delta$ **
  
]

$$Model_1: t \sim \frac{\bar{x}}{se}+\delta$$
.slightly-smaller[
where $\delta$ is **Cauchy-distributed** with $scale = r$
    
]

.right[

.slightly-smaller[
(Jeffreys, 1961; Rouder, *et al*, 2009)
]
]

---

### The Cauchy Distribution, a.k.a. *The Witch of Agnesi*
  
.pull-left[
.slightly-smaller[
      
The **standard Cauchy Distribution** is a $t$-distribution with $df=1$.
      
> The **scale** parameter stretches and squishes it; the **location parameter** slides it left and right on the axis.
      
The figure on the right shows different shapes of the Cauchy distribution given the **standard options** for describing the prior $\delta$ distribution in the `BayesFactor` package.
      
]
]

.pull-right[
```{r echo=FALSE, fig.width = 5, fig.height = 5.5}
  x<-seq(-4, 4, 8/1000)
  
  y1<-dcauchy(x, scale = 0.5)
  y2<-dcauchy(x, scale = sqrt(2)/2)
  y3<-dcauchy(x, scale = 1)
  
  data.frame(x = rep(x, 3),
             y = c(y1, y2, y3),
             color=rep(c("Medium: r = 0.5",
                         "Wide: r = 0.707",
                         "Ultrawide: r = 1"),
                       each=length(x))) %>% 
    ggplot(aes(x, y, color=color))+
    geom_line(linewidth = 1.5)+
    theme_tufte(ticks=FALSE)+
    theme_xaringan(css_file = "soundmachine.css")+
    scale_color_viridis_d(name=NULL,
                          breaks = c("Medium: r = 0.5",
                                     "Wide: r = 0.707",
                                     "Ultrawide: r = 1"))+
    theme(legend.position="bottom",
          legend.direction="vertical",
          axis.title = element_text(size=18),
          axis.text = element_text(size=12),
          legend.text = element_text(size=18))+
    labs(y="density")
```
  
]
---
### Bayesian $t$-test Inference

.slightly-smaller[
The **Cauchy distribution** on the **effect size $\delta$ ** represents the **prior probabilities** for the Bayesian Inference 

> We can change the **scale** of the prior distribution to fit our **prior beliefs** about the expected **Effect size**.

> In the `BayesFactor` package, **medium**, **wide**, and **ultrawide** are built in, but we can choose any reasonable value we want.

The key output is the **Bayes Factor**, which indicates the probability of the **alternative model** *relative to* the **null model**

The software also provides **posterior estimates** (estimated using **MCMC modeling**) on the **mean**, the **variance** and the **effect size**.
]
---

### Bayes Factor Guidelines

.pull-left[
```{r echo=FALSE}
BF1<-c("1 to 3.2", "3.2 to 10", "10 to 100", "> 100")
Interp1<-c("Barely worth mentioning", "Substantial", "Strong", "Decisive")

BFGuide<-data.frame(BF1, Interp1)
kable(BFGuide, "html", booktabs=TRUE, col.names=c("Bayes Factor", "Interpretation")) %>% 
  kable_styling() %>% 
  add_header_above(c("Jeffreys (1961)"=2))
```

]

.pull-right[

```{r echo=FALSE}
BF2<-c("1 to 3", "3 to 20", "20 to 150", "> 150")
Interp2<-c("Not worth more than a bare mention", "Positive", "Strong", "Very Strong")

BFGuide<-data.frame(BF2, Interp2)
kable(BFGuide, "html", booktabs=TRUE, col.names=c("Bayes Factor", "Interpretation")) %>% 
  kable_styling() %>% 
  add_header_above(c("Kass & Raftery (1995)"=2))
```

]
---

### One-sample Bayesian $t$-tests in `R`
  
```{r}
library(BayesFactor)
ttestBF(c(8, 5, 16, 2, 19))

```

---
  
### Repeated-measures Bayesian $t$-tests in `R`

```{r echo=FALSE}
Participant<-c("Sterling",
               "Lana",
               "Pam",
               "Cheryl",
               "Cyril")

Pretest<-c(8.1,
           11.3,
           7.6,
           15.9,
           10.9)

Posttest<-c(6.3,
            10.8,
            4.1,
            15.8,
            10.0)

rm_ex_data<-data.frame(Participant,
                        Pretest,
                        Posttest) %>% 
  mutate(differences = Posttest - Pretest)
```

  
```{r}
ttestBF(Pretest, Posttest, paired=TRUE)

```

---

### Independent Groups Bayesian $t$-tests in `R`

```{r echo=FALSE}
Group1<-c(11.5, 10.7, 8.8, 9.0, 10.0)
Group2<-c(15.0, 14.5, 16.7, 14.8, 15.5)
```

```{r}
ttestBF(Group1, Group2, paired=FALSE)
```
---

### Posterior parameter estimation

```{r eval = FALSE}
summary(posterior(ttestBF(Group1, Group2, paired=FALSE), iterations=5000))
```

.small-code[
```{r echo=FALSE}

#PosteriorEstimates<-summary(posterior(ttestBF(Group1, Group2, paired=FALSE), iterations=5000))
#save(PosteriorEstimates, file = "PosteriorEstimatesforslides.RData")
load("PosteriorEstimatesforslides.RData")

PosteriorEstimates
```

]